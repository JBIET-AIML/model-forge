# ğŸ† Hackathon Problem Statement

## **TextGPT 2026: AI vs Human Text Classification**

---

## ğŸ“Œ Background

As artificial intelligence becomes increasingly adept at generating human-like text, distinguishing between AI-generated and human-written content has real-world importance in:

* Academic integrity and plagiarism detection
* Online content moderation
* Fake news and misinformation detection
* Authorship attribution
* AI safety and accountability

Modern large-language models (LLMs) generate fluent and coherent text, making it non-trivial to distinguish AI vs human writing based solely on surface cues. This challenge explores fine-grained linguistic patterns, stylistic nuances, and semantic traits to build robust classifiers.

---

# ğŸ¯ Core Objective

Participants must build models that classify sentences as:

| Label | Meaning       |
| ----- | ------------- |
| 1     | Human-written |
| 0     | AI-generated  |

Using a labeled dataset where each sentence is annotated as human or AI.

---

# ğŸ“Š Dataset Description

You will be using the **Human vs AI Sentences** dataset from Hugging Face:

This dataset includes thousands of short text samples labeled according to whether they were written by a human or generated by an AI.

Typical characteristics of the dataset:

* Balanced classes (approx. equal human and AI samples)
* Short to medium length text
* Mixed topics
* Diverse writing styles

---

# ğŸ§  Challenge Tasks

## 1ï¸âƒ£ Binary Text Classification

Build a model that predicts:

* **1** â†’ Human-written sentence
* **0** â†’ AI-generated sentence

You may use any approach, such as:

### âœ… Traditional NLP

* TF-IDF + Logistic Regression
* n-grams + SVM
* Bag-of-Words
* Feature engineering (length, punctuation, word rarity)

### âœ… Deep Learning

* LSTM / GRU

### âœ… Transformer-based

* BERT / RoBERTa / DistilBERT / others
* Fine-tuned LLMs

### âœ… Ensemble Models

Two or more of the above approaches combined.

> Models must be trained using only the provided dataset unless external datasets are explicitly permitted.

---

## 2ï¸âƒ£ Explainability (Bonus)

In addition to classification accuracy, teams may be evaluated on how well they explain their model decisions.

Explainability may include:

* Feature importance
* Attention visualization
* Model introspection

---

# ğŸ“ Data Split

Participants must follow a strict time-series safe or random stratified split:

| Split      | Usage |
| ---------- | ----- |
| Train      | 70%   |
| Validation | 15%   |
| Test       | 15%   |

If dataset already includes official splits, use those.

---

# ğŸ“ Evaluation Metrics

Solutions will be judged on:

### Primary Metrics

* **F1-score**
* **Accuracy**

### Secondary Metrics

* Precision
* Recall
* AUC-ROC

---

# ğŸ† Scoring Breakdown

| Component                  | Weight |
| -------------------------- | ------ |
| Classification F1-score    | 40%    |
| Accuracy                   | 30%    |
| Validation Methodology     | 10%    |
| Model Explainability       | 10%    |
| Creativity & Documentation | 10%    |

---

# âš™ Rules & Constraints

* No future data usage or leakage
* Models must be reproducible
* All preprocessing steps must be documented
* External pretrained models (e.g., BERT) are allowed but must be disclosed
* Use of proprietary datasets is prohibited unless explicitly permitted
* Models must run within time and memory constraints defined by the hackathon

---

# ğŸ“œ Deliverables

Participants must submit:

1. Trained model weights / checkpoints
2. Inference code
3. Predictions on the test set
4. Written report including:

   * Methodology
   * Model architecture
   * Feature engineering
   * Evaluation results
   * Explanation of chosen approach
5. (Optional) Visualizations and interpretability analysis

---